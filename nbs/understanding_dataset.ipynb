{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Optional\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "pd.set_option('display.precision', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understand Autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6532, 14)\n",
      "(3225, 14)\n",
      "(2003, 14)\n",
      "(1403, 14)\n"
     ]
    }
   ],
   "source": [
    "# load all questions\n",
    "path = \"../benchmark/data/autocast/autocast_questions.json\"\n",
    "df = pd.read_json(path)\n",
    "print(df.shape)\n",
    "\n",
    "# filter out non-true/false questions\n",
    "df = df[df[\"qtype\"] == \"t/f\"].reset_index(drop=True)\n",
    "print(df.shape)\n",
    "\n",
    "# make sure answers is not None\n",
    "df = df[df[\"answer\"].notnull()].reset_index(drop=True)\n",
    "print(df.shape)\n",
    "\n",
    "# make sure source_links is not []\n",
    "df = df[df[\"source_links\"].map(len) > 0].reset_index(drop=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_links'] = df['source_links'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min          1.00000\n",
       "max       2088.00000\n",
       "mean        36.64362\n",
       "median       5.00000\n",
       "Name: num_links, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min, max, mean, median\n",
    "df['num_links'].agg(['min', 'max', 'mean', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25      3.0\n",
       "0.50      5.0\n",
       "0.75     30.0\n",
       "0.90     99.0\n",
       "0.95    178.7\n",
       "0.99    441.6\n",
       "Name: num_links, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quantiles\n",
    "df['num_links'].quantile([0.25, 0.5, .75, .9, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_links\n",
       "1     170\n",
       "2     167\n",
       "3     156\n",
       "4     150\n",
       "5     107\n",
       "6      71\n",
       "7      48\n",
       "8      62\n",
       "9      27\n",
       "10     15\n",
       "11     14\n",
       "12      7\n",
       "13      5\n",
       "14      2\n",
       "15      4\n",
       "16      3\n",
       "17      1\n",
       "18      4\n",
       "19      2\n",
       "20      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts\n",
    "df['num_links'].value_counts().sort_index()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract source_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(\n",
    "    html: str,\n",
    "    num_words: Optional[int],\n",
    ") -> str:\n",
    "    \"\"\"Extract text from a single HTML document\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()\n",
    "    text = soup.get_text()\n",
    "\n",
    "    return text\n",
    "\n",
    "def get_html(url: str) -> Optional[str]:\n",
    "    \"\"\"Get the HTML of a single URL\"\"\"\n",
    "    filter_words = [\n",
    "        \"facebook\",\n",
    "        \"twitter\",\n",
    "        \"youtube\",\n",
    "        \"instagram\",\n",
    "        \"pinterest\",\n",
    "        \"linkedin\",\n",
    "        \"bloomberg\",\n",
    "    ]\n",
    "\n",
    "    if any([word in url.lower() for word in filter_words]):\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"error\": True,\n",
    "            \"error_message\": \"filtered\",\n",
    "            \"text\": None,\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        response.raise_for_status()\n",
    "        html = response.text\n",
    "        text = extract_text(html, num_words=1000)\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"error\": False,\n",
    "            \"error_message\": None,\n",
    "            \"text\": text,\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"error\": True,\n",
    "            \"error_message\": str(e),\n",
    "            \"text\": None,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47357"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_questions = [q for questions in df[\"source_links\"] for q in questions if q not in [\"\", None]]\n",
    "all_questions = list(set(all_questions))\n",
    "len(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47357/47357 [00:00<00:00, 50477.20it/s]\n",
      "  5%|▍         | 2316/47357 [07:08<2:32:52,  4.91it/s]/var/folders/l_/g22b1g_n0gn4tmx9lkxqv5x00000gn/T/ipykernel_47172/1006404430.py:6: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html, \"html.parser\")\n",
      " 52%|█████▏    | 24485/47357 [1:17:02<46:15,  8.24it/s]  /Users/arshath/miniforge3/lib/python3.10/html/parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n",
      "100%|██████████| 47357/47357 [2:21:33<00:00,  5.58it/s]  \n"
     ]
    }
   ],
   "source": [
    "NUM_WORKERS = 10\n",
    "retrieved_docs = {}\n",
    "\n",
    "# use concurrent.futures to speed up the process; use tqdm to track progress\n",
    "with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "    futures = []\n",
    "    for url in tqdm(all_questions):\n",
    "        future = executor.submit(get_html, url)\n",
    "        futures.append(future)\n",
    "    \n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        result = future.result()\n",
    "        retrieved_docs[result[\"url\"]] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"retrieved_docs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(retrieved_docs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse extracted source_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display index x\n",
    "\n",
    "# ind = 34\n",
    "# for i, (k, v) in enumerate(retrieved_docs.items()):\n",
    "#     if ind == i:\n",
    "#         print(f\"URL: {k}\")\n",
    "#         print(f\"Error: {v['error']}\")\n",
    "#         print(f\"Error message: {v['error_message']}\")\n",
    "#         display(HTML(v['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"retrieved_docs.pkl\", \"rb\") as f:\n",
    "    retrieved_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47357, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df = pd.DataFrame(retrieved_docs).T.reset_index(drop=True)\n",
    "docs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19261, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df_error = docs_df[docs_df[\"error\"] == True].reset_index(drop=True)\n",
    "docs_df_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28096, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df_no_error = docs_df[docs_df[\"error\"] == False].reset_index(drop=True)\n",
    "docs_df_no_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_no_error_links(row):\n",
    "    count = 0\n",
    "    for link in row[\"source_links\"]:\n",
    "        if link in docs_df_no_error[\"url\"].values:\n",
    "            count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "df[\"num_no_error_links\"] = df.apply(count_no_error_links, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"num_no_error_links\"].value_counts().sort_index()[3:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_no_error_links\n",
       "3     149\n",
       "4     135\n",
       "5      83\n",
       "6      51\n",
       "7      41\n",
       "8      30\n",
       "9      11\n",
       "10     10\n",
       "11      5\n",
       "12      4\n",
       "13      2\n",
       "14     10\n",
       "15      5\n",
       "16     10\n",
       "17      8\n",
       "18     12\n",
       "19      7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"num_no_error_links\"].value_counts().sort_index()[3:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"num_no_error_links\"].value_counts().sort_index()[5:20].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df_no_error['num_words'] = docs_df_no_error['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25      647.75\n",
       "0.50     1095.00\n",
       "0.75     1836.00\n",
       "0.90     4334.50\n",
       "0.95    10097.25\n",
       "0.99    39763.75\n",
       "Name: num_words, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df_no_error['num_words'].quantile([0.25, 0.50, .75, .9, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of source links that are more than n words\n",
    "def count_num_words(row, n):\n",
    "    count = 0\n",
    "    for link in row[\"source_links\"]:\n",
    "        if link in docs_df_no_error[\"url\"].values:\n",
    "            num_words = docs_df_no_error[docs_df_no_error[\"url\"] == link][\"num_words\"].values[0]\n",
    "            if num_words > n:\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "df[\"num_words_1000\"] = df.apply(lambda x: count_num_words(x, 1000), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"num_words_1000\"].value_counts().sort_index()[3:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"num_words_1000\"].value_counts().sort_index()[5:].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
